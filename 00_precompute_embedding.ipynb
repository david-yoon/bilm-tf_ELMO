{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read dataset, vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Q', 'A', 'L', 'N'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./data/processed/WikiQACorpus_ELMO/train_token.pkl', 'rb') as f:\n",
    "    trainset = pickle.load(f)\n",
    "    \n",
    "with open('./data/processed/WikiQACorpus_ELMO/dev_token.pkl', 'rb') as f:\n",
    "    devset = pickle.load(f)\n",
    "    \n",
    "with open('./data/processed/WikiQACorpus_ELMO/test_token.pkl', 'rb') as f:\n",
    "    testset = pickle.load(f)\n",
    "    \n",
    "trainset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original dic size =  30102\n",
      "add <S>, <\\S>, dic size =  30104\n"
     ]
    }
   ],
   "source": [
    "dic = []\n",
    "with open('./data/processed/WikiQACorpus/dic.pkl', 'rb') as f:\n",
    "    dic = pickle.load(f)\n",
    "\n",
    "print ('original dic size = ', len(dic))\n",
    "dic['<S>'] = len(dic) + 1\n",
    "dic['<\\S>'] = len(dic) + 1\n",
    "\n",
    "print ('add <S>, <\\S>, dic size = ', len(dic))\n",
    "\n",
    "with open('./data/processed/WikiQACorpus_ELMO/vocab.txt', 'w') as f:\n",
    "    for key,val in dic.items():\n",
    "        f.write( key + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate EMLO embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from bilm import TokenBatcher, BidirectionalLanguageModel, weight_layers, dump_token_embeddings    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway_5.5B/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5'\n",
    "O = 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway_5.5B/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('mkdir ./data/ELMO_pretrain/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dato/workspace/data_space/WikiQA/ELMO_pretrain\n"
     ]
    }
   ],
   "source": [
    "cd ./data/ELMO_pretrain/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('wget ' +  W)\n",
    "os.system('wget ' +  O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_context = [\n",
    "#     'Pretrained biLMs compute representations useful for NLP tasks .',\n",
    "#     'They give state of the art performance for many tasks .'\n",
    "# ]\n",
    "# tokenized_context = [sentence.split() for sentence in raw_context]\n",
    "# tokenized_question = [\n",
    "#     ['What', 'are', 'biLMs', 'useful', 'for', '?'],\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# np.shape(tokenized_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the vocabulary file with all unique tokens and\n",
    "# # the special <S>, </S> tokens (case sensitive).\n",
    "# all_tokens = set(['<S>', '</S>'] + tokenized_question[0])\n",
    "# for context_sentence in tokenized_context:\n",
    "#     for token in context_sentence:\n",
    "#         all_tokens.add(token)\n",
    "# vocab_file = 'vocab_small.txt'\n",
    "# with open(vocab_file, 'w') as fout:\n",
    "#     fout.write('\\n'.join(all_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/dato/workspace/data_space/WikiQA/ELMO_pretrain'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('ln -s ../../ELMO_pretrain/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json ELMO_options.json')\n",
    "os.system('ln -s ../../ELMO_pretrain/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5 ELMO_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('mv ./ELMO_* ../processed/WikiQACorpus_ELMO/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of pretrained LM.  Here we use the test fixtures.\n",
    "datadir = '/home/dato/data_space/WikiQA/processed/WikiQACorpus_ELMO/'\n",
    "options_file = os.path.join(datadir, 'ELMO_options.json')\n",
    "weight_file = os.path.join(datadir, 'ELMO_weights.hdf5')\n",
    "vocab_file =  os.path.join(datadir, 'vocab.txt')\n",
    "token_embedding_file =  os.path.join(datadir, 'WikiQA_elmo_token_embeddings.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/dato/data_space/WikiQA/processed/WikiQACorpus_ELMO/WikiQA_elmo_token_embeddings.hdf5'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dato/workspace/bilm-tf_ELMO/bilm/model.py:384: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n",
      "USING SKIP CONNECTIONS\n"
     ]
    }
   ],
   "source": [
    "# Dump the token embeddings to a file. Run this once for your dataset.\n",
    "dump_token_embeddings(\n",
    "    vocab_file, options_file, weight_file, token_embedding_file\n",
    ")\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now we can do inference.\n",
    "# Create a TokenBatcher to map text to token ids.\n",
    "batcher = TokenBatcher(vocab_file)\n",
    "\n",
    "# Input placeholders to the biLM.\n",
    "context_token_ids = tf.placeholder('int32', shape=(None, None))\n",
    "question_token_ids = tf.placeholder('int32', shape=(None, None))\n",
    "\n",
    "# Build the biLM graph.\n",
    "bilm = BidirectionalLanguageModel(\n",
    "    options_file,\n",
    "    weight_file,\n",
    "    use_character_inputs=False,\n",
    "    embedding_weight_file=token_embedding_file\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "WARNING:tensorflow:From /home/dato/workspace/bilm-tf_ELMO/bilm/elmo.py:89: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n"
     ]
    }
   ],
   "source": [
    "# Get ops to compute the LM embeddings.\n",
    "context_embeddings_op = bilm(context_token_ids)\n",
    "question_embeddings_op = bilm(question_token_ids)\n",
    "\n",
    "# Get an op to compute ELMo (weighted average of the internal biLM layers)\n",
    "# Our SQuAD model includes ELMo at both the input and output layers\n",
    "# of the task GRU, so we need 4x ELMo representations for the question\n",
    "# and context at each of the input and output.\n",
    "# We use the same ELMo weights for both the question and context\n",
    "# at each of the input and output.\n",
    "elmo_context_input = weight_layers('input', context_embeddings_op, l2_coef=0.0)\n",
    "with tf.variable_scope('', reuse=True):\n",
    "    # the reuse=True scope reuses weights from the context for the question\n",
    "    elmo_question_input = weight_layers(\n",
    "        'input', question_embeddings_op, l2_coef=0.0\n",
    "    )\n",
    "\n",
    "elmo_context_output = weight_layers(\n",
    "    'output', context_embeddings_op, l2_coef=0.0\n",
    ")\n",
    "\n",
    "with tf.variable_scope('', reuse=True):\n",
    "    # the reuse=True scope reuses weights from the context for the question\n",
    "    elmo_question_output = weight_layers(\n",
    "        'output', question_embeddings_op, l2_coef=0.0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenized_context' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-4286b67ca62e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenized_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenized_context' is not defined"
     ]
    }
   ],
   "source": [
    "tokenized_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_ids = batcher.batch_sentences(tokenized_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Pretrained', 'biLMs', 'compute', 'representations', 'useful', 'for', 'NLP', 'tasks', '.'], ['They', 'give', 'state', 'of', 'the', 'art', 'performance', 'for', 'many', 'tasks', '.']]\n",
      "(2,)\n",
      "(9,)\n",
      "(11,)\n"
     ]
    }
   ],
   "source": [
    "print (tokenized_context)\n",
    "print (np.shape(tokenized_context))\n",
    "print (np.shape(tokenized_context[0]))\n",
    "print (np.shape(tokenized_context[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['What', 'are', 'biLMs', 'useful', 'for', '?']]\n",
      "(1, 6)\n"
     ]
    }
   ],
   "source": [
    "print (tokenized_question)\n",
    "print (np.shape(tokenized_question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create batches of data.\n",
    "context_ids = batcher.batch_sentences(tokenized_context)\n",
    "question_ids = batcher.batch_sentences(tokenized_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30103     0     0 16855  6219 26728  7921     0 15576   294     0     0\n",
      "      0]\n",
      " [30103   205 11348 25997 14030  9732 29360  4412  7921 15791 15576   294\n",
      "      0]]\n",
      "(2, 13)\n"
     ]
    }
   ],
   "source": [
    "print (context_ids)\n",
    "print (np.shape(context_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30103 12290 29366     0 26728  7921 18591     0]]\n",
      "(1, 8)\n"
     ]
    }
   ],
   "source": [
    "print (question_ids)\n",
    "print (np.shape(question_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    # It is necessary to initialize variables once before running inference.\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Create batches of data.\n",
    "    context_ids = batcher.batch_sentences(tokenized_context)\n",
    "    question_ids = batcher.batch_sentences(tokenized_question)\n",
    "\n",
    "    # Compute ELMo representations (here for the input only, for simplicity).\n",
    "    elmo_context_input_, elmo_question_input_ = sess.run(\n",
    "        [elmo_context_input['weighted_op'], elmo_question_input['weighted_op']],\n",
    "        feed_dict={context_token_ids: context_ids,\n",
    "                   question_token_ids: question_ids}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['What', 'are', 'biLMs', 'useful', 'for', '?']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(tokenized_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Pretrained',\n",
       "  'biLMs',\n",
       "  'compute',\n",
       "  'representations',\n",
       "  'useful',\n",
       "  'for',\n",
       "  'NLP',\n",
       "  'tasks',\n",
       "  '.'],\n",
       " ['They',\n",
       "  'give',\n",
       "  'state',\n",
       "  'of',\n",
       "  'the',\n",
       "  'art',\n",
       "  'performance',\n",
       "  'for',\n",
       "  'many',\n",
       "  'tasks',\n",
       "  '.']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(tokenized_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6, 1024)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(elmo_question_input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 11, 1024)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(elmo_context_input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02462964,  0.16383222,  0.2964051 , ..., -0.12922229,\n",
       "        -0.2930111 ,  0.13189684],\n",
       "       [-0.57287556, -0.07158805, -0.24308902, ..., -0.11735731,\n",
       "        -0.2677825 , -0.06677829],\n",
       "       [-0.8419022 ,  0.2892721 , -0.3882361 , ..., -0.21937613,\n",
       "        -0.16024263, -0.09764783],\n",
       "       ...,\n",
       "       [-0.03325855,  0.00599727, -0.12481157, ...,  0.27898324,\n",
       "         0.55338466, -0.18398118],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elmo_context_input_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.24442434, -0.3860852 ,  0.09052717, ...,  0.12260772,\n",
       "        -0.01382168, -0.06875429],\n",
       "       [-0.338963  ,  0.02178424,  0.22192626, ..., -0.35271585,\n",
       "         0.26657373, -0.27544504],\n",
       "       [-0.35692668, -0.32613516,  0.2805973 , ...,  0.00421192,\n",
       "         0.09699225,  0.09507689],\n",
       "       ...,\n",
       "       [-0.06032594, -0.07026625,  0.0918818 , ..., -0.2848844 ,\n",
       "        -0.19069   , -0.19516918],\n",
       "       [ 0.06933622, -0.30043387,  0.1031775 , ..., -0.5641655 ,\n",
       "         0.21887177, -0.06783633],\n",
       "       [ 0.04119237, -0.06924646,  0.01466054, ...,  0.27898324,\n",
       "         0.55338466, -0.18398118]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elmo_context_input_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf110_p36]",
   "language": "python",
   "name": "conda-env-tf110_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
